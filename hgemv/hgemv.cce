#ifdef __CCE_KT_TEST__
#define __aicore__
#else
#define __aicore__ [aicore]
#endif
// CAmodel 不需要头文件
#ifndef CAMODEL

#include "kernel_operator.h"

#endif

using T_INPUT = float;
using T_OUTPUT = float;

constexpr int32_t L0AB_PINGPONG_BUFFER_LEN = 32 * 1024 / sizeof(T_INPUT); // 32KB
constexpr int32_t L0C_PINGPONG_BUFFER_LEN = 64 * 1024 / sizeof(T_INPUT);  // 64KB
constexpr int32_t BLOCK_SIZE = 16;
constexpr int32_t C0_SIZE = 32 / sizeof(T_INPUT);
constexpr int32_t CUBE_MATRIX_SIZE = BLOCK_SIZE * C0_SIZE;               // 16 * 8
constexpr int32_t L1_PINGPONG_BUFFER_LEN = 256 * 1024 / sizeof(T_INPUT); // 256KB

__aicore__ __inline__ void load_matrix_zN(__cbuf__ float *dst, __gm__ float *src,
                                          int32_t R, int32_t C, int32_t valid_row, int32_t valid_col, size_t stride)
{
    constexpr int C0 = 32 / sizeof(float);
    constexpr int STRIDE_LIMIT = 65536;

    if (stride < STRIDE_LIMIT)
    {
        copy_gm_to_cbuf_multi_nd2nz_b32s(
            dst,
            src,
            static_cast<uint8_t>(0),          // sid
            static_cast<uint16_t>(1),         // ndNum
            static_cast<uint16_t>(valid_row), // nValue
            static_cast<uint16_t>(valid_col), // dValue
            static_cast<uint16_t>(0),         // srcNdMatrixStride
            static_cast<uint16_t>(stride),    // srcDValue
            static_cast<uint16_t>(R),         // dstNzC0Stride
            static_cast<uint16_t>(1),         // dstNzNStride
            static_cast<uint16_t>(0)          // dstNzMatrixStride
        );
    }
    else
    {
        for (int i = 0; i < valid_row; i++)
        {
            copy_gm_to_cbuf_multi_nd2nz_b32s(
                dst + i * C0,
                src + i * stride,
                static_cast<uint8_t>(0),          // sid
                static_cast<uint16_t>(1),         // ndNum
                static_cast<uint16_t>(1),         // nValue
                static_cast<uint16_t>(valid_col), // dValue
                static_cast<uint16_t>(0),         // srcNdMatrixStride, unused
                static_cast<uint16_t>(0),         // srcDValue, unused
                static_cast<uint16_t>(R),         // dstNzC0Stride
                static_cast<uint16_t>(0),         // dstNzNStride, unused
                static_cast<uint16_t>(0)          // dstNzMatrixStride, unused
            );
        }
    }
}

__aicore__ __inline__ void load_matrix_zZ(__cbuf__ float *dst, __gm__ float *src,
                                          int32_t R, int32_t C, int32_t valid_row, int32_t valid_col, size_t stride)
{
    constexpr int R0 = 16;
    constexpr int C0 = 32 / sizeof(float);
    constexpr int STRIDE_LIMIT = 65536;

    int64_t srcNdStride = R0 * stride;
    int64_t srcNStride = stride;
    if (srcNdStride < STRIDE_LIMIT)
    {
        int ndNum = valid_row / R0;
        int remains = valid_row % R0;
        if (ndNum > 0)
        {
            copy_gm_to_cbuf_multi_nd2nz_b32s(
                dst,
                src,
                static_cast<uint8_t>(0),            // sid
                static_cast<uint16_t>(ndNum),       // ndNum
                static_cast<uint16_t>(R0),          // nValue
                static_cast<uint16_t>(valid_col),   // dValue
                static_cast<uint16_t>(srcNdStride), // srcNdMatrixStride
                static_cast<uint16_t>(srcNStride),  // srcDValue
                static_cast<uint16_t>(R0),          // dstNzC0Stride
                static_cast<uint16_t>(1),           // dstNzNStride
                static_cast<uint16_t>(R0 * C)       // dstNzMatrixStride
            );
        }
        if (remains > 0)
        {
            copy_gm_to_cbuf_multi_nd2nz_b32s(
                dst + ndNum * R0 * C,
                src + ndNum * R0 * stride,
                static_cast<uint8_t>(0),           // sid
                static_cast<uint16_t>(1),          // ndNum
                static_cast<uint16_t>(remains),    // nValue
                static_cast<uint16_t>(valid_col),  // dValue
                static_cast<uint16_t>(0),          // srcNdMatrixStride
                static_cast<uint16_t>(srcNStride), // srcDValue
                static_cast<uint16_t>(R0),         // dstNzC0Stride
                static_cast<uint16_t>(1),          // dstNzNStride
                static_cast<uint16_t>(0)           // dstNzMatrixStride
            );
        }
    }
    else if (srcNStride < STRIDE_LIMIT)
    {
        int ndNum = valid_row / R0;
        int remains = valid_row % R0;
        for (int i = 0; i < ndNum; i++)
        {
            copy_gm_to_cbuf_multi_nd2nz_b32s(
                dst + i * R0 * C,
                src + i * R0 * stride,
                static_cast<uint8_t>(0),           // sid
                static_cast<uint16_t>(1),          // ndNum
                static_cast<uint16_t>(R0),         // nValue
                static_cast<uint16_t>(valid_col),  // dValue
                static_cast<uint16_t>(0),          // srcNdMatrixStride
                static_cast<uint16_t>(srcNStride), // srcDValue
                static_cast<uint16_t>(R0),         // dstNzC0Stride
                static_cast<uint16_t>(1),          // dstNzNStride
                static_cast<uint16_t>(0)           // dstNzMatrixStride
            );
        }
        if (remains > 0)
        {
            copy_gm_to_cbuf_multi_nd2nz_b32s(
                dst + ndNum * R0 * C,
                src + ndNum * R0 * stride,
                static_cast<uint8_t>(0),           // sid
                static_cast<uint16_t>(1),          // ndNum
                static_cast<uint16_t>(remains),    // nValue
                static_cast<uint16_t>(valid_col),  // dValue
                static_cast<uint16_t>(0),          // srcNdMatrixStride
                static_cast<uint16_t>(srcNStride), // srcDValue
                static_cast<uint16_t>(R0),         // dstNzC0Stride
                static_cast<uint16_t>(1),          // dstNzNStride
                static_cast<uint16_t>(0)           // dstNzMatrixStride
            );
        }
    }
    else
    {
        for (int i = 0; i < valid_row; i++)
        {
            int idxR0 = i / R0;
            int idxInR0 = i % R0;
            copy_gm_to_cbuf_multi_nd2nz_b32s(
                dst + idxR0 * R0 * C + idxR0 * C0,
                src + i * stride,
                static_cast<uint8_t>(0),          // sid
                static_cast<uint16_t>(1),         // ndNum
                static_cast<uint16_t>(1),         // nValue
                static_cast<uint16_t>(valid_col), // dValue
                static_cast<uint16_t>(0),         // srcNdMatrixStride, unused
                static_cast<uint16_t>(0),         // srcDValue, unused
                static_cast<uint16_t>(R0),        // dstNzC0Stride
                static_cast<uint16_t>(0),         // dstNzNStride, unused
                static_cast<uint16_t>(0)          // dstNzMatrixStride, unused
            );
        }
    }
}

// CAmodel 需要将参数写入到tiling_para_gm中
#ifdef CAMODEL
#else
extern "C" __global__ __aicore__ void dynamic_op_matmul_kernel(
    __gm__ T_INPUT *__restrict__ gm_a,
    __gm__ T_INPUT *__restrict__ gm_b,
    __gm__ T_OUTPUT *__restrict__ gm_c,
    int32_t batchSize,
    int32_t trans_a,
    int32_t trans_b,
    int32_t M,
    int32_t N,
    int32_t K,
    int32_t lda,
    int32_t ldb,
    int32_t ldc,
    int M0,
    int N0,
    int K0)
#endif
{
    set_padding(0);
    set_atomic_none();
    uint64_t config = 0x1;
    set_nd_para(config);
// CAmodel 从tiling_para_gm解析出参数
#ifdef CAMODEL
#endif
}

#ifndef CAMODEL
void hgemv(
    int trans,
    int m,
    int n,
    const half *alpha,
    const half *A,
    int lda,
    const half *x,
    int incx,
    const half *beta,
    half *y,
    int incy)
{

}
#endif
